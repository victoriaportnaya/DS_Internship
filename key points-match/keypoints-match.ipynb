{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4745574,"sourceType":"datasetVersion","datasetId":2746265}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Satellite Image Feature Matching with SuperPoint and SuperGlue\n\nThis script performs feature matching between pairs of satellite images using the SuperPoint and SuperGlue models. It detects and matches keypoints between images, which can be useful for monitoring environmental changes such as deforestation.","metadata":{"_uuid":"3c9293db-134b-469e-8a52-67721b7f025c","_cell_guid":"9ff51f47-78d9-4a08-a06a-363f759f8c5e","trusted":true}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom PIL import Image\nfrom glob import glob\nfrom torchvision import transforms","metadata":{"_uuid":"2c18ff21-3593-4f94-a2dc-b6c704ebf656","_cell_guid":"c5ec279c-e6b9-419c-b467-5708a1125eb9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:17:28.611610Z","iopub.execute_input":"2024-10-25T19:17:28.613721Z","iopub.status.idle":"2024-10-25T19:17:33.614765Z","shell.execute_reply.started":"2024-10-25T19:17:28.613666Z","shell.execute_reply":"2024-10-25T19:17:33.613666Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Install and Import Required Libraries\nInstall necessary libraries for image processing and deep learning and import them.","metadata":{"_uuid":"ceedebaf-64b6-45df-b5ec-a5301bbfeba0","_cell_guid":"82dbb3f4-b179-4668-a5b6-0b354d5693ac","trusted":true}},{"cell_type":"code","source":"!pip install --upgrade torch torchvision kornia ","metadata":{"_uuid":"1bc3335d-3737-4ada-ac0a-ac2523537cd2","_cell_guid":"1b7fb515-e71e-4b6d-95a2-5e01bb132adc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:19:25.835426Z","iopub.execute_input":"2024-10-25T19:19:25.835913Z","iopub.status.idle":"2024-10-25T19:22:53.210165Z","shell.execute_reply.started":"2024-10-25T19:19:25.835852Z","shell.execute_reply":"2024-10-25T19:22:53.208023Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nCollecting torch\n  Using cached torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0+cpu)\nCollecting torchvision\n  Using cached torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: kornia in /opt/conda/lib/python3.10/site-packages (0.7.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.1.0 (from torch)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting sympy==1.13.1 (from torch)\n  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: kornia-rs>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from kornia) (0.1.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from kornia) (21.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->kornia) (3.1.2)\nDownloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m964.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m825.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.12\n    Uninstalling sympy-1.12:\n      Successfully uninstalled sympy-1.12\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0+cpu\n    Uninstalling torch-2.4.0+cpu:\n      Successfully uninstalled torch-2.4.0+cpu\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.0+cpu\n    Uninstalling torchvision-0.19.0+cpu:\n      Successfully uninstalled torchvision-0.19.0+cpu\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.0 which is incompatible.\ntorchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.0 torchvision-0.20.0 triton-3.1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 2: Clone and Set Up SuperGlue Repository\nClone the SuperGlue repository and add it to the system path to access the necessary models and utilities.","metadata":{"_uuid":"1a40ba58-95ed-4df4-96bd-a54a4e9547e3","_cell_guid":"ea6989e4-bb64-412d-b2e2-fa5e7bbda3cf","trusted":true}},{"cell_type":"code","source":"!git clone https://github.com/magicleap/SuperGluePretrainedNetwork.git\nimport sys\nsys.path.append('./SuperGluePretrainedNetwork')","metadata":{"_uuid":"18aaedf6-47bc-431f-84c5-9bcba68f0ada","_cell_guid":"ffa8002f-e283-46a1-8876-c3b7a448020d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:17:37.321635Z","iopub.execute_input":"2024-10-25T19:17:37.322125Z","iopub.status.idle":"2024-10-25T19:17:46.056945Z","shell.execute_reply.started":"2024-10-25T19:17:37.322073Z","shell.execute_reply":"2024-10-25T19:17:46.055475Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'SuperGluePretrainedNetwork'...\nremote: Enumerating objects: 185, done.\u001b[K\nremote: Counting objects: 100% (3/3), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 185 (delta 0), reused 2 (delta 0), pack-reused 182 (from 1)\u001b[K\nReceiving objects: 100% (185/185), 118.85 MiB | 22.48 MiB/s, done.\nResolving deltas: 100% (52/52), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install supergluepy","metadata":{"execution":{"iopub.status.busy":"2024-10-25T19:23:56.741074Z","iopub.execute_input":"2024-10-25T19:23:56.741522Z","iopub.status.idle":"2024-10-25T19:23:58.995740Z","shell.execute_reply.started":"2024-10-25T19:23:56.741483Z","shell.execute_reply":"2024-10-25T19:23:58.994193Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement supergluepy (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for supergluepy\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 3: Import Matching Modules\nImport the `Matching` class and utility functions for reading images and visualizing matches.","metadata":{"_uuid":"872c5a4e-b734-4275-a695-6a68bc391c7f","_cell_guid":"159ef184-4db3-4e75-ab70-c6265488febc","trusted":true}},{"cell_type":"code","source":"from models.matching import Matching\nfrom models.utils import read_image, make_matching_plot","metadata":{"_uuid":"b73ae381-4d2d-42f5-9af2-6a92fde63e45","_cell_guid":"2afe1904-d099-43c9-86f0-a0aac2be0f35","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:24:19.506200Z","iopub.execute_input":"2024-10-25T19:24:19.507272Z","iopub.status.idle":"2024-10-25T19:24:19.512164Z","shell.execute_reply.started":"2024-10-25T19:24:19.507225Z","shell.execute_reply":"2024-10-25T19:24:19.510914Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Define Helper Functions\nDefine helper functions to locate pairs of satellite images and load them. These functions organize images by date and band, making them ready for feature matching.","metadata":{"_uuid":"e23d1cdb-7bbc-4e86-b7c4-cec13c5ea8a0","_cell_guid":"922217a6-fe37-4647-95ec-6b47098619bf","trusted":true}},{"cell_type":"code","source":"!pip install rasterio","metadata":{"execution":{"iopub.status.busy":"2024-10-25T19:25:03.347104Z","iopub.execute_input":"2024-10-25T19:25:03.348061Z","iopub.status.idle":"2024-10-25T19:25:16.158568Z","shell.execute_reply.started":"2024-10-25T19:25:03.348007Z","shell.execute_reply":"2024-10-25T19:25:16.157265Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from rasterio) (23.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from rasterio) (2024.8.30)\nRequirement already satisfied: click>=4.0 in /opt/conda/lib/python3.10/site-packages (from rasterio) (8.1.7)\nRequirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.1.1)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from rasterio) (3.1.2)\nDownloading rasterio-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import rasterio\n\ndef find_image_pairs(data_dir):\n    images_by_tile = {}\n    for root, dirs, files in os.walk(data_dir):\n        for file in files:\n            if file.endswith('.jp2'):\n                filepath = os.path.join(root, file)\n                filename = os.path.basename(filepath)\n                parts = filename.split('_')\n                if len(parts) >= 3:\n                    tile = parts[0]\n                    date = parts[1][:8]  # YYYYMMDD\n                    band_part = parts[-1]\n                    band = band_part.split('.')[0]\n                    key = (tile, date)\n                    if key not in images_by_tile:\n                        images_by_tile[key] = {}\n                    images_by_tile[key][band] = filepath\n\n    tile_dates = {}\n    for (tile, date), bands in images_by_tile.items():\n        if tile not in tile_dates:\n            tile_dates[tile] = []\n        tile_dates[tile].append((date, bands))\n    for tile in tile_dates:\n        tile_dates[tile].sort()\n\n    image_pairs = []\n    for tile in tile_dates:\n        dates_bands = tile_dates[tile]\n        for i in range(len(dates_bands) - 1):\n            date1, bands1 = dates_bands[i]\n            date2, bands2 = dates_bands[i+1]\n            required_bands = {'B02', 'B03', 'B04'}\n            if required_bands.issubset(bands1.keys()) and required_bands.issubset(bands2.keys()):\n                image_pairs.append(((bands1['B02'], bands1['B03'], bands1['B04']),\n                                    (bands2['B02'], bands2['B03'], bands2['B04'])))\n    return image_pairs\n\ndef load_sentinel2_image(band_paths):\n    try:\n        with rasterio.open(band_paths[0]) as blue_src, \\\n             rasterio.open(band_paths[1]) as green_src, \\\n             rasterio.open(band_paths[2]) as red_src:\n            blue = blue_src.read(1)\n            green = green_src.read(1)\n            red = red_src.read(1)\n            image = np.stack((red, green, blue), axis=-1)\n            image_gray = cv2.cvtColor((image / np.max(image) * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n            return image_gray, image\n    except Exception as e:\n        print(f'Error loading bands: {e}')\n        return None, None","metadata":{"_uuid":"ee1a75d6-115b-4b3c-a822-3d9efa222452","_cell_guid":"991585dc-2452-49fb-b10f-050430e0ffdf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:25:17.227124Z","iopub.execute_input":"2024-10-25T19:25:17.228385Z","iopub.status.idle":"2024-10-25T19:25:17.641561Z","shell.execute_reply.started":"2024-10-25T19:25:17.228333Z","shell.execute_reply":"2024-10-25T19:25:17.640321Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Load and Preprocess Images\nIdentify image pairs, load one pair, and resize them to a standard size for processing.","metadata":{"_uuid":"d5405d9b-49b6-437d-828f-d026ae4095a8","_cell_guid":"9b462822-88b6-431b-92ee-250d2e4f5f5a","trusted":true}},{"cell_type":"code","source":"data_dir = '/kaggle/input/deforestation-in-ukraine'\nimage_pairs = find_image_pairs(data_dir)\n(band_paths1), (band_paths2) = image_pairs[5]\nimage0_gray, image0_color = load_sentinel2_image(band_paths1)\nimage1_gray, image1_color = load_sentinel2_image(band_paths2)\nimage0_gray = cv2.resize(image0_gray, (640, 480))\nimage1_gray = cv2.resize(image1_gray, (640, 480))","metadata":{"_uuid":"36ea22ea-ca78-470c-92e4-47e58e36e103","_cell_guid":"528f9995-e248-4f07-8869-4badf379379f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:25:23.789765Z","iopub.execute_input":"2024-10-25T19:25:23.790857Z","iopub.status.idle":"2024-10-25T19:26:16.120801Z","shell.execute_reply.started":"2024-10-25T19:25:23.790809Z","shell.execute_reply":"2024-10-25T19:26:16.119381Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Step 6: Configure and Run the Matching Model\nConfigure SuperPoint and SuperGlue, then perform feature matching on the selected image pair.","metadata":{"_uuid":"5c43483d-09d0-43ae-b962-fbddacd58d31","_cell_guid":"b7993660-b207-4f50-83ed-435e200829fd","trusted":true}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nconfig = {\n    'superpoint': {\n        'nms_radius': 4,\n        'keypoint_threshold': 0.005,\n        'max_keypoints': 1024,\n    },\n    'superglue': {\n        'weights': 'outdoor',\n        'sinkhorn_iterations': 20,\n        'match_threshold': 0.2,\n    }\n}\nmatching = Matching(config).eval().to(device)\n\ninp0 = torch.from_numpy(image0_gray / 255.).float()[None, None].to(device)\ninp1 = torch.from_numpy(image1_gray / 255.).float()[None, None].to(device)\nwith torch.no_grad():\n    pred = matching({'image0': inp0, 'image1': inp1})\nkeypoints0 = pred['keypoints0'][0].cpu().numpy()\nkeypoints1 = pred['keypoints1'][0].cpu().numpy()\nmatches = pred['matches0'][0].cpu().numpy()\nconfidence = pred['matching_scores0'][0].cpu().numpy()","metadata":{"_uuid":"1855c33b-26ba-45e2-9fe5-2a59cdb1e455","_cell_guid":"88a33382-9cd7-4d6e-81d7-e44472351d99","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:26:16.123287Z","iopub.execute_input":"2024-10-25T19:26:16.123721Z","iopub.status.idle":"2024-10-25T19:26:18.934485Z","shell.execute_reply.started":"2024-10-25T19:26:16.123679Z","shell.execute_reply":"2024-10-25T19:26:18.933448Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/kaggle/working/./SuperGluePretrainedNetwork/models/superpoint.py:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.load_state_dict(torch.load(str(path)))\n/kaggle/working/./SuperGluePretrainedNetwork/models/superglue.py:226: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.load_state_dict(torch.load(str(path)))\n","output_type":"stream"},{"name":"stdout","text":"Loaded SuperPoint model\nLoaded SuperGlue model (\"outdoor\" weights)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 7: Filter and Visualize Matches\nFilter the valid matches and visualize the matched keypoints.","metadata":{"_uuid":"4c2c472f-3db7-459b-acf8-b2bdd42c713f","_cell_guid":"e2281e6c-d50a-4cb5-946a-b439c7a1ced5","trusted":true}},{"cell_type":"code","source":"valid = matches > -1\nmkpts0 = keypoints0[valid]\nmkpts1 = keypoints1[matches[valid]]\nmconf = confidence[valid]\n\ncolor = plt.cm.jet(mconf)\nmake_matching_plot(\n    cv2.cvtColor(image0_color, cv2.COLOR_RGB2GRAY),\n    cv2.cvtColor(image1_color, cv2.COLOR_RGB2GRAY),\n    keypoints0, keypoints1, mkpts0, mkpts1, color,\n    text=['SuperGlue Feature Matching', f'Keypoints: {len(keypoints0)}:{len(keypoints1)}', f'Matches: {len(mkpts0)}'],\n    path='matches.png', show_keypoints=True, opencv_display=False\n)\nplt.figure(figsize=(20, 10))\nmatched_img = plt.imread('matches.png')\nplt.imshow(matched_img, cmap='gray')\nplt.title('Keypoint Matches Between Images Using SuperPoint and SuperGlue')\nplt.axis('off')\nplt.show()","metadata":{"_uuid":"39fe3589-aae5-4d3b-9151-8a6dc3d02834","_cell_guid":"a783c7a7-c7b8-45ae-a467-b94c6efd2ca2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-25T19:26:31.325363Z","iopub.execute_input":"2024-10-25T19:26:31.325735Z","iopub.status.idle":"2024-10-25T19:26:43.845846Z","shell.execute_reply.started":"2024-10-25T19:26:31.325695Z","shell.execute_reply":"2024-10-25T19:26:43.844691Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions and Possible Improvements\n\n- **Dataset Diversity**: This setup currently handles a specific format and a single data source. Expanding to include additional satellite sources or image types could make the model more robust across datasets.\n- **Error Handling**: Improved error handling in the `load_sentinel2_image` function would enhance reliability, particularly for large-scale batch processing.\n- **Hyperparameter Tuning**: Fine-tuning model parameters like `keypoint_threshold` and `match_threshold` could yield more accurate results.\n- **RANSAC Filtering**: Adding RANSAC (Random Sample Consensus) could filter outliers, improving match quality for specific applications.\n- **Scalability**: To handle larger datasets, consider batch processing or parallel processing to improve efficiency.","metadata":{"_uuid":"d0ceed22-700f-4b99-bf86-294568b16b19","_cell_guid":"186b5e3c-5ae6-46bc-92f7-38c94861424c","trusted":true}}]}